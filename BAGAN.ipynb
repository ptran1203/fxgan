{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BAGAN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptran1203/gan_project/blob/master/BAGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqAhBY2Qm7M7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97d52888-e048-4e4e-e822-e94ad636fc86"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gYUSJ8pnoJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from google.colab import drive, output\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!rm -rf '/content/gan_project'\n",
        "!git clone https://github.com/ptran1203/gan_project\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "output.clear()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-ekhuj6nrNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4dc94d7-d8e9-4974-8115-d649e1235caf"
      },
      "source": [
        "cd gan_project"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gan_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oImN0Awnnurt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "59c8efe3-852b-4c41-c36d-ffb0ec49d1d1"
      },
      "source": [
        "BASE_DIR = '/content/drive/My Drive/bagan'\n",
        "DS_DIR = '/content/drive/My Drive/bagan/dataset/chest_xray'\n",
        "DS_SAVE_DIR = '/content/drive/My Drive/bagan/dataset/save'\n",
        "gratio_mode = 'uniform'\n",
        "dratio_mode = 'uniform'\n",
        "\n",
        "from bagan import *\n",
        "from batch_gen import *\n",
        "from utils import *\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "\n",
        "def create_dir_if_any(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "class Bagan(BalancingGAN):\n",
        "    def _build_common_encoder(self, image, min_latent_res=8):\n",
        "        resolution = self.resolution\n",
        "        channels = self.channels\n",
        "\n",
        "        # build a relatively standard conv net, with LeakyReLUs as suggested in ACGAN\n",
        "        cnn = Sequential()\n",
        "\n",
        "        cnn.add(Conv2D(128, (5, 5), padding='same', strides=(2, 2)))\n",
        "        cnn.add(LeakyReLU(alpha=0.2))\n",
        "        cnn.add(Dropout(0.3))\n",
        "            \n",
        "        cnn.add(Conv2D(256, (5, 5), padding='same', strides=(2, 2)))\n",
        "        cnn.add(LeakyReLU(alpha=0.2))\n",
        "        cnn.add(Dropout(0.3))\n",
        "\n",
        "        cnn.add(Conv2D(512, (5, 5), padding='same', strides=(2, 2)))\n",
        "        cnn.add(LeakyReLU(alpha=0.2))\n",
        "        cnn.add(Dropout(0.3))\n",
        "\n",
        "        cnn.add(Flatten())\n",
        "\n",
        "        features = cnn(image)\n",
        "        return features\n",
        "\n",
        "    # def backup_point(self, epoch): return\n",
        "\n",
        "\n",
        "class BatchGen(BatchGenerator):\n",
        "    to_train_classes = INVERT_CATEGORIES_MAP[:2]\n",
        "    to_test_classes = list(range(81, 86))\n",
        "\n",
        "\n",
        "is_test = 0\n",
        "## Test batch GEN\n",
        "if is_test:\n",
        "    bg = BatchGen(BatchGen.TRAIN, 64, 'multi_chest', 64)\n",
        "    labels = np.array([0, 0, 1, 1, 2, 2, 3 ,1])\n",
        "    samples = bg.ramdom_kshot_images(4, labels)\n",
        "    print(samples.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh60L-YIn7JG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "965d518f-b5eb-4f30-861b-74b52eff3639"
      },
      "source": [
        "gan_epochs  = 400000\n",
        "adam_lr = 0.0004\n",
        "batch_size = 128\n",
        "# dataset_name should be \"flowers\", \"chest\", \"multi_chest\"\n",
        "# \"chest\" is binary classification, \"multi_chest\" using chest-xray14 dataset\n",
        "dataset_name = 'multi_chest'\n",
        "latent_size = 128\n",
        "# Use resnet architecture for Generator\n",
        "resnet = False\n",
        "# Use self-attention mechanism\n",
        "attention = False\n",
        "np.random.seed(0)\n",
        "# Image resoulution\n",
        "rst = 64\n",
        "is_prune = True\n",
        "\n",
        "prune = [500, 500] if is_prune else None\n",
        "\n",
        "res_dir = BASE_DIR + '/result/bagan_{}_{}_v2'.format(dataset_name,rst)\n",
        "create_dir_if_any(res_dir)\n",
        "\n",
        "bg_train_full = BatchGen(BatchGen.TRAIN, batch_size, dataset_name, rst,prune_classes=prune)\n",
        "bg_test = BatchGen(BatchGen.TEST, batch_size, dataset_name, rst)\n",
        "channels = bg_train_full.dataset_x[0].shape[-1]\n",
        "shape = bg_train_full.dataset_x[0].shape\n",
        "\n",
        "print('img shape', shape)\n",
        "classes = bg_train_full.get_label_table()\n",
        "target_classes = np.array(range(len(classes)))\n",
        "target_class_id = 0 # train to balance this class\n",
        "print('Class counters: ', bg_train_full.per_class_count)\n",
        "gan = Bagan(\n",
        "    target_classes,\n",
        "    target_class_id,\n",
        "    adam_lr=adam_lr,\n",
        "    latent_size=latent_size,\n",
        "    res_dir=res_dir,\n",
        "    image_shape=shape,\n",
        "    min_latent_res=4,\n",
        "    autoenc_epochs=50\n",
        ")\n",
        "gan.train(bg_train_full, bg_test, epochs=gan_epochs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load data from /content/drive/My Drive/bagan/dataset/multi_chest/imgs_labels_64.pkl successfully\n",
            "2000 2000\n",
            "Remove 500 items in class 0\n",
            "Remove 500 items in class 1\n",
            "load data from /content/drive/My Drive/bagan/dataset/multi_chest/imgs_labels_64.pkl successfully\n",
            "10679 10679\n",
            "img shape (64, 64, 1)\n",
            "Class counters:  [500, 500]\n",
            "BAGAN init_autoenc\n",
            "BAGAN: training autoencoder\n",
            "Autoencoder train epoch: 1/100\n",
            "Autoencoder train epoch: 2/100\n",
            "Autoencoder train epoch: 3/100\n",
            "Autoencoder train epoch: 4/100\n",
            "Autoencoder train epoch: 5/100\n",
            "Autoencoder train epoch: 6/100\n",
            "Autoencoder train epoch: 7/100\n",
            "Autoencoder train epoch: 8/100\n",
            "Autoencoder train epoch: 9/100\n",
            "Autoencoder train epoch: 10/100\n",
            "Autoencoder train epoch: 11/100\n",
            "Autoencoder train epoch: 12/100\n",
            "Autoencoder train epoch: 13/100\n",
            "Autoencoder train epoch: 14/100\n",
            "Autoencoder train epoch: 15/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20dRojXM2ohB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(latent_size, init_resolution=8):\n",
        "        resolution = 64\n",
        "        channels = 1\n",
        "        init_channels = 256\n",
        "        cnn = Sequential()\n",
        "\n",
        "        cnn.add(Dense(init_channels * init_resolution * init_resolution, input_dim=latent_size))\n",
        "        cnn.add(BatchNormalization())\n",
        "        cnn.add(LeakyReLU())\n",
        "        cnn.add(Reshape((init_resolution, init_resolution, init_channels)))\n",
        "       \n",
        "        crt_res = init_resolution\n",
        "        # upsample\n",
        "        while crt_res < resolution/2:\n",
        "            cnn.add(Conv2DTranspose(\n",
        "                init_channels, kernel_size = 5, strides = 2, padding='same'))\n",
        "            cnn.add(LeakyReLU(alpha=0.02))\n",
        "            init_channels //= 2\n",
        "            crt_res = crt_res * 2\n",
        "            assert crt_res <= resolution,\\\n",
        "                \"Error: final resolution [{}] must equal i*2^n. Initial resolution i is [{}]. n must be a natural number.\".format(resolution, init_resolution)\n",
        "        cnn.add(Conv2DTranspose(\n",
        "                    1, kernel_size = 5,\n",
        "                    strides = 2, padding='same',\n",
        "                    activation='tanh'))\n",
        "\n",
        "        latent = Input(shape=(latent_size, ))\n",
        "\n",
        "        fake_image_from_latent = cnn(latent)\n",
        "        return Model(inputs=latent, outputs=fake_image_from_latent)\n",
        "\n",
        "model = build_generator(128, 4)\n",
        "model.layers[1].summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}